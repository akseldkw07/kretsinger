{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kret_np_pd._core.np_pd_nb_imports] Imported kret_np_pd._core.np_pd_nb_imports in 0.0224 seconds\n",
      "Loaded environment variables from /Users/Akseldkw/coding/kretsinger/.env\n",
      "[kret_lgbm._core.lgbm_nb_imports] Imported kret_lgbm._core.lgbm_nb_imports in 0.0007 seconds\n",
      "[kret_lightning._core.lightning_nb_imports] Imported kret_lightning._core.lightning_nb_imports in 0.0032 seconds\n",
      "[kret_matplotlib._core.mpl_nb_imports] Imported kret_matplotlib._core.mpl_nb_imports in 0.0745 seconds\n",
      "[kret_optuna._core.optuna_nb_imports] Imported kret_optuna._core.optuna_nb_imports in 0.0002 seconds\n",
      "[kret_polars._core.polars_nb_imports] Imported kret_polars._core.polars_nb_imports in 0.0784 seconds\n",
      "[kret_rosetta._core.rosetta_nb_imports] Imported kret_rosetta._core.rosetta_nb_imports in 0.0000 seconds\n",
      "[kret_sklearn._core.sklearn_nb_imports] Imported kret_sklearn._core.sklearn_nb_imports in 0.1319 seconds\n",
      "[kret_torch_utils._core.torch_nb_imports] Imported kret_torch_utils._core.torch_nb_imports in 0.4648 seconds\n",
      "[kret_tqdm._core.tqdm_nb_imports] Imported kret_tqdm._core.tqdm_nb_imports in 0.0002 seconds\n",
      "[kret_type_hints._core.types_nb_imports] Imported kret_type_hints._core.types_nb_imports in 0.0006 seconds\n",
      "[kret_utils._core.utils_nb_imports] Imported kret_utils._core.utils_nb_imports in 0.0008 seconds\n"
     ]
    }
   ],
   "source": [
    "from kret_notebook import *  # NOTE import first\n",
    "from kret_lgbm._core.lgbm_nb_imports import *\n",
    "from kret_lightning._core.lightning_nb_imports import *\n",
    "from kret_matplotlib._core.mpl_nb_imports import *\n",
    "from kret_np_pd._core.np_pd_nb_imports import *\n",
    "from kret_optuna._core.optuna_nb_imports import *\n",
    "from kret_polars._core.polars_nb_imports import *\n",
    "from kret_rosetta._core.rosetta_nb_imports import *\n",
    "from kret_sklearn._core.sklearn_nb_imports import *\n",
    "from kret_torch_utils._core.torch_nb_imports import *\n",
    "from kret_tqdm._core.tqdm_nb_imports import *\n",
    "from kret_type_hints._core.types_nb_imports import *\n",
    "from kret_utils._core.utils_nb_imports import *\n",
    "\n",
    "# from kret_wandb._core.wandb_nb_imports import *  # NOTE this is slow to import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kret_lightning.examples.cifar10_module import *\n",
    "from kret_lightning.examples.cifar10_datamodule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dm = CIFAR10DataModule(UKS_CONSTANTS.DATA_DIR / \"CIFAR10\", batch_size=64, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar_dm.train_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdvancedCNN(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout2d(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=8192, out_features=8192, bias=True)\n",
      "  (fc2): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Define the CNN model\n",
    "class AdvancedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AdvancedCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32 * 2, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32 * 2, out_channels=64 * 2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64 * 2, out_channels=64 * 2, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64 * 2, out_channels=128 * 2, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=128 * 2, out_channels=128 * 2, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=128 * 2, out_channels=128 * 2, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(in_channels=128 * 2, out_channels=256 * 2, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(in_channels=256 * 2, out_channels=256 * 2, kernel_size=3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(in_channels=256 * 2, out_channels=256 * 2, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32 * 2)\n",
    "        self.bn2 = nn.BatchNorm2d(128 * 2)\n",
    "        self.bn3 = nn.BatchNorm2d(256 * 2)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout2d(0.2)\n",
    "\n",
    "        self.fc1 = nn.Linear(4096 * 2, 4096 * 2)\n",
    "        self.fc2 = nn.Linear(4096 * 2, 2048 * 2)\n",
    "        self.fc3 = nn.Linear(2048 * 2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.relu(self.bn2(self.conv4(x)))\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.relu(self.conv6(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.relu(self.bn3(self.conv7(x)))\n",
    "        x = self.relu(self.conv8(x))\n",
    "        x = self.relu(self.conv9(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiating the network and printing its architecture\n",
    "num_classes = 10\n",
    "net = AdvancedCNN(num_classes)\n",
    "print(net)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params:  108,316,554\n"
     ]
    }
   ],
   "source": [
    "print(f\"Params:  {count_parameters(net):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving hparams, ignoring ()\n",
      "Saving hparams, ignoring ()\n"
     ]
    }
   ],
   "source": [
    "cifar_nn = CIFAR10ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params:  2,777,674\n"
     ]
    }
   ],
   "source": [
    "print(f\"Params:  {count_parameters(cifar_nn):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchview import ComputationGraph, draw_graph\n",
    "\n",
    "batch_size = 1\n",
    "# device='meta' -> no memory is consumed for visualization\n",
    "model_graph: ComputationGraph = draw_graph(\n",
    "    cifar_nn, input_size=(batch_size, 3, 32, 32), device=\"mps\", expand_nested=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.1.1 (0)\n",
       " -->\n",
       "<!-- Title: model Pages: 1 -->\n",
       "<svg width=\"191pt\" height=\"886pt\"\n",
       " viewBox=\"0.00 0.00 191.00 886.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.756941 0.756941) rotate(0) translate(4 1166.5)\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1166.5 248,-1166.5 248,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"8,-8 8,-1122 236,-1122 236,-8 8,-8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"33.62\" y=\"-1106.6\" font-family=\"Times,serif\" font-size=\"12.00\">ResNet</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"19,-646.5 19,-805.75 225,-805.75 225,-646.5 19,-646.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"51.75\" y=\"-790.35\" font-family=\"Times,serif\" font-size=\"12.00\">Sequential</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-479.25 16,-638.5 228,-638.5 228,-479.25 16,-479.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"48.75\" y=\"-623.1\" font-family=\"Times,serif\" font-size=\"12.00\">Sequential</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster_5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-312 16,-471.25 228,-471.25 228,-312 16,-312\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"48.75\" y=\"-455.85\" font-family=\"Times,serif\" font-size=\"12.00\">Sequential</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"185.25,-1162.5 58.75,-1162.5 58.75,-1130 185.25,-1130 185.25,-1162.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"58.75,-1130 58.75,-1162.5 119.75,-1162.5 119.75,-1130 58.75,-1130\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"63.75\" y=\"-1148\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"73.12\" y=\"-1136.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"119.75,-1130 119.75,-1162.5 185.25,-1162.5 185.25,-1130 119.75,-1130\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"124.75\" y=\"-1142.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 3, 32, 32)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"202.25,-1091.75 41.75,-1091.75 41.75,-1049.25 202.25,-1049.25 202.25,-1091.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"41.75,-1049.25 41.75,-1091.75 85.5,-1091.75 85.5,-1049.25 41.75,-1049.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"46.75\" y=\"-1072.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"47.5\" y=\"-1061\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"85.5,-1070.5 85.5,-1091.75 128.5,-1091.75 128.5,-1070.5 85.5,-1070.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"95\" y=\"-1077.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"128.5,-1070.5 128.5,-1091.75 202.25,-1091.75 202.25,-1070.5 128.5,-1070.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"136.12\" y=\"-1077.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 3, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"85.5,-1049.25 85.5,-1070.5 128.5,-1070.5 128.5,-1049.25 85.5,-1049.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"90.5\" y=\"-1056\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"128.5,-1049.25 128.5,-1070.5 202.25,-1070.5 202.25,-1049.25 128.5,-1049.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"133.5\" y=\"-1056\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-1130.33C122,-1122.51 122,-1112.63 122,-1103.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-1103.23 122,-1093.23 118.5,-1103.23 125.5,-1103.23\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"215.38,-1013.25 28.62,-1013.25 28.62,-970.75 215.38,-970.75 215.38,-1013.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"28.62,-970.75 28.62,-1013.25 98.62,-1013.25 98.62,-970.75 28.62,-970.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"33.62\" y=\"-993.75\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"47.5\" y=\"-982.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98.62,-992 98.62,-1013.25 141.62,-1013.25 141.62,-992 98.62,-992\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"108.12\" y=\"-998.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"141.62,-992 141.62,-1013.25 215.38,-1013.25 215.38,-992 141.62,-992\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"146.62\" y=\"-998.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98.62,-970.75 98.62,-992 141.62,-992 141.62,-970.75 98.62,-970.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"103.62\" y=\"-977.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"141.62,-970.75 141.62,-992 215.38,-992 215.38,-970.75 141.62,-970.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"146.62\" y=\"-977.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-1049.4C122,-1041.82 122,-1033 122,-1024.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-1024.74 122,-1014.74 118.5,-1024.74 125.5,-1024.74\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"201.5,-934.75 42.5,-934.75 42.5,-892.25 201.5,-892.25 201.5,-934.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"42.5,-892.25 42.5,-934.75 84.75,-934.75 84.75,-892.25 42.5,-892.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"55.75\" y=\"-915.25\" font-family=\"Linux libertine\" font-size=\"10.00\">relu</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"47.5\" y=\"-904\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"84.75,-913.5 84.75,-934.75 127.75,-934.75 127.75,-913.5 84.75,-913.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"94.25\" y=\"-920.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"127.75,-913.5 127.75,-934.75 201.5,-934.75 201.5,-913.5 127.75,-913.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"132.75\" y=\"-920.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"84.75,-892.25 84.75,-913.5 127.75,-913.5 127.75,-892.25 84.75,-892.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"89.75\" y=\"-899\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"127.75,-892.25 127.75,-913.5 201.5,-913.5 201.5,-892.25 127.75,-892.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"132.75\" y=\"-899\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-970.9C122,-963.32 122,-954.5 122,-946.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-946.24 122,-936.24 118.5,-946.24 125.5,-946.24\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"202.62,-856.25 41.38,-856.25 41.38,-813.75 202.62,-813.75 202.62,-856.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"41.38,-813.75 41.38,-856.25 85.88,-856.25 85.88,-813.75 41.38,-813.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"46.38\" y=\"-836.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"47.5\" y=\"-825.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"85.88,-835 85.88,-856.25 128.88,-856.25 128.88,-835 85.88,-835\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"95.38\" y=\"-841.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"128.88,-835 128.88,-856.25 202.62,-856.25 202.62,-835 128.88,-835\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"133.88\" y=\"-841.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"85.88,-813.75 85.88,-835 128.88,-835 128.88,-813.75 85.88,-813.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"90.88\" y=\"-820.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"128.88,-813.75 128.88,-835 202.62,-835 202.62,-813.75 128.88,-813.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"133.88\" y=\"-820.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-892.4C122,-884.82 122,-876 122,-867.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-867.74 122,-857.74 118.5,-867.74 125.5,-867.74\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"216.88,-775.5 27.12,-775.5 27.12,-733 216.88,-733 216.88,-775.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27.12,-733 27.12,-775.5 100.12,-775.5 100.12,-733 27.12,-733\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"32.12\" y=\"-756\" font-family=\"Linux libertine\" font-size=\"10.00\">ResidualBlock</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"47.5\" y=\"-744.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100.12,-754.25 100.12,-775.5 143.12,-775.5 143.12,-754.25 100.12,-754.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"109.62\" y=\"-761\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143.12,-754.25 143.12,-775.5 216.88,-775.5 216.88,-754.25 143.12,-754.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"148.12\" y=\"-761\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100.12,-733 100.12,-754.25 143.12,-754.25 143.12,-733 100.12,-733\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"105.12\" y=\"-739.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143.12,-733 143.12,-754.25 216.88,-754.25 216.88,-733 143.12,-733\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"148.12\" y=\"-739.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-814.13C122,-805.8 122,-795.91 122,-786.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-786.9 122,-776.9 118.5,-786.9 125.5,-786.9\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"216.88,-697 27.12,-697 27.12,-654.5 216.88,-654.5 216.88,-697\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27.12,-654.5 27.12,-697 100.12,-697 100.12,-654.5 27.12,-654.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"32.12\" y=\"-677.5\" font-family=\"Linux libertine\" font-size=\"10.00\">ResidualBlock</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"47.5\" y=\"-666.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100.12,-675.75 100.12,-697 143.12,-697 143.12,-675.75 100.12,-675.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"109.62\" y=\"-682.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143.12,-675.75 143.12,-697 216.88,-697 216.88,-675.75 143.12,-675.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"148.12\" y=\"-682.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"100.12,-654.5 100.12,-675.75 143.12,-675.75 143.12,-654.5 100.12,-654.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"105.12\" y=\"-661.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"143.12,-654.5 143.12,-675.75 216.88,-675.75 216.88,-654.5 143.12,-654.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"148.12\" y=\"-661.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-733.15C122,-725.57 122,-716.75 122,-708.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-708.49 122,-698.49 118.5,-708.49 125.5,-708.49\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"219.5,-608.25 24.5,-608.25 24.5,-565.75 219.5,-565.75 219.5,-608.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-565.75 24.5,-608.25 97.5,-608.25 97.5,-565.75 24.5,-565.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"29.5\" y=\"-588.75\" font-family=\"Linux libertine\" font-size=\"10.00\">ResidualBlock</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"44.88\" y=\"-577.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97.5,-587 97.5,-608.25 140.5,-608.25 140.5,-587 97.5,-587\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"107\" y=\"-593.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140.5,-587 140.5,-608.25 219.5,-608.25 219.5,-587 140.5,-587\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"148.12\" y=\"-593.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97.5,-565.75 97.5,-587 140.5,-587 140.5,-565.75 97.5,-565.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"102.5\" y=\"-572.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140.5,-565.75 140.5,-587 219.5,-587 219.5,-565.75 140.5,-565.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"145.5\" y=\"-572.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 16, 16) </text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-654.63C122,-644.12 122,-631.02 122,-619.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-619.52 122,-609.52 118.5,-619.52 125.5,-619.52\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"219.5,-529.75 24.5,-529.75 24.5,-487.25 219.5,-487.25 219.5,-529.75\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-487.25 24.5,-529.75 97.5,-529.75 97.5,-487.25 24.5,-487.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"29.5\" y=\"-510.25\" font-family=\"Linux libertine\" font-size=\"10.00\">ResidualBlock</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"44.88\" y=\"-499\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97.5,-508.5 97.5,-529.75 140.5,-529.75 140.5,-508.5 97.5,-508.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"107\" y=\"-515.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140.5,-508.5 140.5,-529.75 219.5,-529.75 219.5,-508.5 140.5,-508.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"145.5\" y=\"-515.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 16, 16) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97.5,-487.25 97.5,-508.5 140.5,-508.5 140.5,-487.25 97.5,-487.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"102.5\" y=\"-494\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140.5,-487.25 140.5,-508.5 219.5,-508.5 219.5,-487.25 140.5,-487.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"145.5\" y=\"-494\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 16, 16) </text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-565.9C122,-558.32 122,-549.5 122,-541.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-541.24 122,-531.24 118.5,-541.24 125.5,-541.24\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"219.5,-441 24.5,-441 24.5,-398.5 219.5,-398.5 219.5,-441\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24.5,-398.5 24.5,-441 97.5,-441 97.5,-398.5 24.5,-398.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"29.5\" y=\"-421.5\" font-family=\"Linux libertine\" font-size=\"10.00\">ResidualBlock</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"44.88\" y=\"-410.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97.5,-419.75 97.5,-441 140.5,-441 140.5,-419.75 97.5,-419.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"107\" y=\"-426.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140.5,-419.75 140.5,-441 219.5,-441 219.5,-419.75 140.5,-419.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"145.5\" y=\"-426.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 128, 16, 16) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"97.5,-398.5 97.5,-419.75 140.5,-419.75 140.5,-398.5 97.5,-398.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"102.5\" y=\"-405.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"140.5,-398.5 140.5,-419.75 219.5,-419.75 219.5,-398.5 140.5,-398.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"150.75\" y=\"-405.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256, 8, 8) </text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-487.38C122,-476.87 122,-463.77 122,-451.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-452.27 122,-442.27 118.5,-452.27 125.5,-452.27\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"214.25,-362.5 29.75,-362.5 29.75,-320 214.25,-320 214.25,-362.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"29.75,-320 29.75,-362.5 102.75,-362.5 102.75,-320 29.75,-320\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"34.75\" y=\"-343\" font-family=\"Linux libertine\" font-size=\"10.00\">ResidualBlock</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"50.12\" y=\"-331.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.75,-341.25 102.75,-362.5 145.75,-362.5 145.75,-341.25 102.75,-341.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"112.25\" y=\"-348\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"145.75,-341.25 145.75,-362.5 214.25,-362.5 214.25,-341.25 145.75,-341.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"150.75\" y=\"-348\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256, 8, 8) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.75,-320 102.75,-341.25 145.75,-341.25 145.75,-320 102.75,-320\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"107.75\" y=\"-326.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"145.75,-320 145.75,-341.25 214.25,-341.25 214.25,-320 145.75,-320\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"150.75\" y=\"-326.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256, 8, 8) </text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-398.65C122,-391.07 122,-382.25 122,-373.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-373.99 122,-363.99 118.5,-373.99 125.5,-373.99\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"225.5,-284 18.5,-284 18.5,-241.5 225.5,-241.5 225.5,-284\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"18.5,-241.5 18.5,-284 114,-284 114,-241.5 18.5,-241.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"23.5\" y=\"-264.5\" font-family=\"Linux libertine\" font-size=\"10.00\">AdaptiveAvgPool2d</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"50.12\" y=\"-253.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"114,-262.75 114,-284 157,-284 157,-262.75 114,-262.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"123.5\" y=\"-269.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"157,-262.75 157,-284 225.5,-284 225.5,-262.75 157,-262.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"162\" y=\"-269.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256, 8, 8) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"114,-241.5 114,-262.75 157,-262.75 157,-241.5 114,-241.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"119\" y=\"-248.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"157,-241.5 157,-262.75 225.5,-262.75 225.5,-241.5 157,-241.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"162\" y=\"-248.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256, 1, 1) </text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-320.15C122,-312.57 122,-303.75 122,-295.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-295.49 122,-285.49 118.5,-295.49 125.5,-295.49\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"198.88,-205.5 45.12,-205.5 45.12,-163 198.88,-163 198.88,-205.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"45.12,-163 45.12,-205.5 87.38,-205.5 87.38,-163 45.12,-163\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"56.12\" y=\"-186\" font-family=\"Linux libertine\" font-size=\"10.00\">view</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"50.12\" y=\"-174.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"87.38,-184.25 87.38,-205.5 130.38,-205.5 130.38,-184.25 87.38,-184.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"96.88\" y=\"-191\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"130.38,-184.25 130.38,-205.5 198.88,-205.5 198.88,-184.25 130.38,-184.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"135.38\" y=\"-191\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256, 1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"87.38,-163 87.38,-184.25 130.38,-184.25 130.38,-163 87.38,-163\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"92.38\" y=\"-169.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"130.38,-163 130.38,-184.25 198.88,-184.25 198.88,-163 130.38,-163\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"146.62\" y=\"-169.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256) </text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-241.65C122,-234.07 122,-225.25 122,-216.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-216.99 122,-206.99 118.5,-216.99 125.5,-216.99\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"187.62,-127 56.38,-127 56.38,-84.5 187.62,-84.5 187.62,-127\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"56.38,-84.5 56.38,-127 98.62,-127 98.62,-84.5 56.38,-84.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"64.38\" y=\"-107.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"61.38\" y=\"-96.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98.62,-105.75 98.62,-127 141.62,-127 141.62,-105.75 98.62,-105.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"108.12\" y=\"-112.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"141.62,-105.75 141.62,-127 187.62,-127 187.62,-105.75 141.62,-105.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"146.62\" y=\"-112.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 256) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"98.62,-84.5 98.62,-105.75 141.62,-105.75 141.62,-84.5 98.62,-84.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"103.62\" y=\"-91.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"141.62,-84.5 141.62,-105.75 187.62,-105.75 187.62,-84.5 141.62,-84.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"149.25\" y=\"-91.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 10) </text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-163.15C122,-155.57 122,-146.75 122,-138.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-138.49 122,-128.49 118.5,-138.49 125.5,-138.49\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"174.38,-48.5 69.62,-48.5 69.62,-16 174.38,-16 174.38,-48.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"69.62,-16 69.62,-48.5 136.62,-48.5 136.62,-16 69.62,-16\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"74.62\" y=\"-34\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"87\" y=\"-22.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"136.62,-16 136.62,-48.5 174.38,-48.5 174.38,-16 136.62,-16\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"141.62\" y=\"-28.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 10)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122,-84.83C122,-77.06 122,-68.03 122,-59.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.5,-59.81 122,-49.81 118.5,-59.81 125.5,-59.81\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x30a2c4b00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CIFAR10ResNet__lr=0.001--warmup=0.1--patience=10--num_blocks=2--num_filters=64--dropout_rate=0.3--num_classes=10'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_nn.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\n",
    "    UKS_CONSTANTS.TORCH_MODEL_VIZ_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `CIFAR10ResNet([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `CIFAR10ResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 45 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 20},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.1',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"x\"<FLOAT,[1,3,32,32]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"linear\"<FLOAT,[1,10]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"model.conv1.weight\"<FLOAT,[64,3,3,3]>{Tensor(...)},\n",
       "                %\"model.layer1.0.conv1.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"model.layer1.0.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"model.layer1.1.conv1.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"model.layer1.1.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"model.layer2.0.conv1.weight\"<FLOAT,[128,64,3,3]>{Tensor(...)},\n",
       "                %\"model.layer2.0.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"model.layer2.0.shortcut.0.weight\"<FLOAT,[128,64,1,1]>{Tensor(...)},\n",
       "                %\"model.layer2.1.conv1.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"model.layer2.1.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"model.layer3.0.conv1.weight\"<FLOAT,[256,128,3,3]>{Tensor(...)},\n",
       "                %\"model.layer3.0.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"model.layer3.0.shortcut.0.weight\"<FLOAT,[256,128,1,1]>{Tensor(...)},\n",
       "                %\"model.layer3.1.conv1.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"model.layer3.1.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"model.fc.weight\"<FLOAT,[10,256]>{TorchTensor(...)},\n",
       "                %\"model.fc.bias\"<FLOAT,[10]>{TorchTensor<FLOAT,[10]>(Parameter containing: tensor([ 0.0115,  0.0377,  0.0551, -0.0523, -0.0025, -0.0262, -0.0353, -0.0382, 0.0453,  0.0261], requires_grad=True), name='model.fc.bias')},\n",
       "                %\"val_140\"<INT64,[2]>{Tensor<INT64,[2]>(array([-1, -2]), name='val_140')},\n",
       "                %\"val_144\"<INT64,[2]>{Tensor<INT64,[2]>(array([ 1, -1]), name='val_144')}\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # node_Conv_192\n",
       "                  %\"getitem\"<FLOAT,[1,64,32,32]> ⬅️ ::Conv(%\"x\", %\"model.conv1.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "             1 |  # node_relu\n",
       "                  %\"relu\"<FLOAT,[1,64,32,32]> ⬅️ ::Relu(%\"getitem\")\n",
       "             2 |  # node_Conv_195\n",
       "                  %\"getitem_3\"<FLOAT,[1,64,32,32]> ⬅️ ::Conv(%\"relu\", %\"model.layer1.0.conv1.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "             3 |  # node_relu_1\n",
       "                  %\"relu_1\"<FLOAT,[1,64,32,32]> ⬅️ ::Relu(%\"getitem_3\")\n",
       "             4 |  # node_Conv_198\n",
       "                  %\"getitem_6\"<FLOAT,[1,64,32,32]> ⬅️ ::Conv(%\"relu_1\", %\"model.layer1.0.conv2.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "             5 |  # node_add\n",
       "                  %\"add\"<FLOAT,[1,64,32,32]> ⬅️ ::Add(%\"getitem_6\", %\"relu\")\n",
       "             6 |  # node_relu_2\n",
       "                  %\"relu_2\"<FLOAT,[1,64,32,32]> ⬅️ ::Relu(%\"add\")\n",
       "             7 |  # node_Conv_201\n",
       "                  %\"getitem_9\"<FLOAT,[1,64,32,32]> ⬅️ ::Conv(%\"relu_2\", %\"model.layer1.1.conv1.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "             8 |  # node_relu_3\n",
       "                  %\"relu_3\"<FLOAT,[1,64,32,32]> ⬅️ ::Relu(%\"getitem_9\")\n",
       "             9 |  # node_Conv_204\n",
       "                  %\"getitem_12\"<FLOAT,[1,64,32,32]> ⬅️ ::Conv(%\"relu_3\", %\"model.layer1.1.conv2.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            10 |  # node_add_1\n",
       "                  %\"add_1\"<FLOAT,[1,64,32,32]> ⬅️ ::Add(%\"getitem_12\", %\"relu_2\")\n",
       "            11 |  # node_relu_4\n",
       "                  %\"relu_4\"<FLOAT,[1,64,32,32]> ⬅️ ::Relu(%\"add_1\")\n",
       "            12 |  # node_Conv_207\n",
       "                  %\"getitem_15\"<FLOAT,[1,128,16,16]> ⬅️ ::Conv(%\"relu_4\", %\"model.layer2.0.conv1.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(2, 2), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            13 |  # node_relu_5\n",
       "                  %\"relu_5\"<FLOAT,[1,128,16,16]> ⬅️ ::Relu(%\"getitem_15\")\n",
       "            14 |  # node_Conv_210\n",
       "                  %\"getitem_18\"<FLOAT,[1,128,16,16]> ⬅️ ::Conv(%\"relu_5\", %\"model.layer2.0.conv2.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            15 |  # node_Conv_213\n",
       "                  %\"getitem_21\"<FLOAT,[1,128,16,16]> ⬅️ ::Conv(%\"relu_4\", %\"model.layer2.0.shortcut.0.weight\"{...}) {group=1, pads=(0, 0, 0, 0), strides=(2, 2), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            16 |  # node_add_2\n",
       "                  %\"add_2\"<FLOAT,[1,128,16,16]> ⬅️ ::Add(%\"getitem_18\", %\"getitem_21\")\n",
       "            17 |  # node_relu_6\n",
       "                  %\"relu_6\"<FLOAT,[1,128,16,16]> ⬅️ ::Relu(%\"add_2\")\n",
       "            18 |  # node_Conv_216\n",
       "                  %\"getitem_24\"<FLOAT,[1,128,16,16]> ⬅️ ::Conv(%\"relu_6\", %\"model.layer2.1.conv1.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            19 |  # node_relu_7\n",
       "                  %\"relu_7\"<FLOAT,[1,128,16,16]> ⬅️ ::Relu(%\"getitem_24\")\n",
       "            20 |  # node_Conv_219\n",
       "                  %\"getitem_27\"<FLOAT,[1,128,16,16]> ⬅️ ::Conv(%\"relu_7\", %\"model.layer2.1.conv2.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            21 |  # node_add_3\n",
       "                  %\"add_3\"<FLOAT,[1,128,16,16]> ⬅️ ::Add(%\"getitem_27\", %\"relu_6\")\n",
       "            22 |  # node_relu_8\n",
       "                  %\"relu_8\"<FLOAT,[1,128,16,16]> ⬅️ ::Relu(%\"add_3\")\n",
       "            23 |  # node_Conv_222\n",
       "                  %\"getitem_30\"<FLOAT,[1,256,8,8]> ⬅️ ::Conv(%\"relu_8\", %\"model.layer3.0.conv1.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(2, 2), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            24 |  # node_relu_9\n",
       "                  %\"relu_9\"<FLOAT,[1,256,8,8]> ⬅️ ::Relu(%\"getitem_30\")\n",
       "            25 |  # node_Conv_225\n",
       "                  %\"getitem_33\"<FLOAT,[1,256,8,8]> ⬅️ ::Conv(%\"relu_9\", %\"model.layer3.0.conv2.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            26 |  # node_Conv_228\n",
       "                  %\"getitem_36\"<FLOAT,[1,256,8,8]> ⬅️ ::Conv(%\"relu_8\", %\"model.layer3.0.shortcut.0.weight\"{...}) {group=1, pads=(0, 0, 0, 0), strides=(2, 2), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            27 |  # node_add_4\n",
       "                  %\"add_4\"<FLOAT,[1,256,8,8]> ⬅️ ::Add(%\"getitem_33\", %\"getitem_36\")\n",
       "            28 |  # node_relu_10\n",
       "                  %\"relu_10\"<FLOAT,[1,256,8,8]> ⬅️ ::Relu(%\"add_4\")\n",
       "            29 |  # node_Conv_231\n",
       "                  %\"getitem_39\"<FLOAT,[1,256,8,8]> ⬅️ ::Conv(%\"relu_10\", %\"model.layer3.1.conv1.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            30 |  # node_relu_11\n",
       "                  %\"relu_11\"<FLOAT,[1,256,8,8]> ⬅️ ::Relu(%\"getitem_39\")\n",
       "            31 |  # node_Conv_234\n",
       "                  %\"getitem_42\"<FLOAT,[1,256,8,8]> ⬅️ ::Conv(%\"relu_11\", %\"model.layer3.1.conv2.weight\"{...}) {group=1, pads=(1, 1, 1, 1), strides=(1, 1), auto_pad='NOTSET', dilations=(1, 1)}\n",
       "            32 |  # node_add_5\n",
       "                  %\"add_5\"<FLOAT,[1,256,8,8]> ⬅️ ::Add(%\"getitem_42\", %\"relu_10\")\n",
       "            33 |  # node_relu_12\n",
       "                  %\"relu_12\"<FLOAT,[1,256,8,8]> ⬅️ ::Relu(%\"add_5\")\n",
       "            34 |  # node_mean\n",
       "                  %\"mean\"<FLOAT,[1,256,1,1]> ⬅️ ::ReduceMean(%\"relu_12\", %\"val_140\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            35 |  # node_view\n",
       "                  %\"view\"<FLOAT,[1,256]> ⬅️ ::Reshape(%\"mean\", %\"val_144\"{[1, -1]}) {allowzero=1}\n",
       "            36 |  # node_linear\n",
       "                  %\"linear\"<FLOAT,[1,10]> ⬅️ ::Gemm(%\"view\", %\"model.fc.weight\"{...}, %\"model.fc.bias\"{[0.011506639420986176, 0.037727534770965576, 0.05507993698120117, -0.05228752642869949, -0.0024539604783058167, -0.02617436647415161, -0.03526061773300171, -0.038167908787727356, 0.04529940336942673, 0.026081204414367676]}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            return %\"linear\"<FLOAT,[1,10]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_model_conv1_weight: \"f32[64, 3, 3, 3]\", p_model_bn1_weight: \"f32[64]\", p_model_bn1_bias: \"f32[64]\", p_model_layer1_0_conv1_weight: \"f32[64, 64, 3, 3]\", p_model_layer1_0_bn1_weight: \"f32[64]\", p_model_layer1_0_bn1_bias: \"f32[64]\", p_model_layer1_0_conv2_weight: \"f32[64, 64, 3, 3]\", p_model_layer1_0_bn2_weight: \"f32[64]\", p_model_layer1_0_bn2_bias: \"f32[64]\", p_model_layer1_1_conv1_weight: \"f32[64, 64, 3, 3]\", p_model_layer1_1_bn1_weight: \"f32[64]\", p_model_layer1_1_bn1_bias: \"f32[64]\", p_model_layer1_1_conv2_weight: \"f32[64, 64, 3, 3]\", p_model_layer1_1_bn2_weight: \"f32[64]\", p_model_layer1_1_bn2_bias: \"f32[64]\", p_model_layer2_0_conv1_weight: \"f32[128, 64, 3, 3]\", p_model_layer2_0_bn1_weight: \"f32[128]\", p_model_layer2_0_bn1_bias: \"f32[128]\", p_model_layer2_0_conv2_weight: \"f32[128, 128, 3, 3]\", p_model_layer2_0_bn2_weight: \"f32[128]\", p_model_layer2_0_bn2_bias: \"f32[128]\", p_model_layer2_0_shortcut_0_weight: \"f32[128, 64, 1, 1]\", p_model_layer2_0_shortcut_1_weight: \"f32[128]\", p_model_layer2_0_shortcut_1_bias: \"f32[128]\", p_model_layer2_1_conv1_weight: \"f32[128, 128, 3, 3]\", p_model_layer2_1_bn1_weight: \"f32[128]\", p_model_layer2_1_bn1_bias: \"f32[128]\", p_model_layer2_1_conv2_weight: \"f32[128, 128, 3, 3]\", p_model_layer2_1_bn2_weight: \"f32[128]\", p_model_layer2_1_bn2_bias: \"f32[128]\", p_model_layer3_0_conv1_weight: \"f32[256, 128, 3, 3]\", p_model_layer3_0_bn1_weight: \"f32[256]\", p_model_layer3_0_bn1_bias: \"f32[256]\", p_model_layer3_0_conv2_weight: \"f32[256, 256, 3, 3]\", p_model_layer3_0_bn2_weight: \"f32[256]\", p_model_layer3_0_bn2_bias: \"f32[256]\", p_model_layer3_0_shortcut_0_weight: \"f32[256, 128, 1, 1]\", p_model_layer3_0_shortcut_1_weight: \"f32[256]\", p_model_layer3_0_shortcut_1_bias: \"f32[256]\", p_model_layer3_1_conv1_weight: \"f32[256, 256, 3, 3]\", p_model_layer3_1_bn1_weight: \"f32[256]\", p_model_layer3_1_bn1_bias: \"f32[256]\", p_model_layer3_1_conv2_weight: \"f32[256, 256, 3, 3]\", p_model_layer3_1_bn2_weight: \"f32[256]\", p_model_layer3_1_bn2_bias: \"f32[256]\", p_model_fc_weight: \"f32[10, 256]\", p_model_fc_bias: \"f32[10]\", b_model_bn1_running_mean: \"f32[64]\", b_model_bn1_running_var: \"f32[64]\", b_model_bn1_num_batches_tracked: \"i64[]\", b_model_layer1_0_bn1_running_mean: \"f32[64]\", b_model_layer1_0_bn1_running_var: \"f32[64]\", b_model_layer1_0_bn1_num_batches_tracked: \"i64[]\", b_model_layer1_0_bn2_running_mean: \"f32[64]\", b_model_layer1_0_bn2_running_var: \"f32[64]\", b_model_layer1_0_bn2_num_batches_tracked: \"i64[]\", b_model_layer1_1_bn1_running_mean: \"f32[64]\", b_model_layer1_1_bn1_running_var: \"f32[64]\", b_model_layer1_1_bn1_num_batches_tracked: \"i64[]\", b_model_layer1_1_bn2_running_mean: \"f32[64]\", b_model_layer1_1_bn2_running_var: \"f32[64]\", b_model_layer1_1_bn2_num_batches_tracked: \"i64[]\", b_model_layer2_0_bn1_running_mean: \"f32[128]\", b_model_layer2_0_bn1_running_var: \"f32[128]\", b_model_layer2_0_bn1_num_batches_tracked: \"i64[]\", b_model_layer2_0_bn2_running_mean: \"f32[128]\", b_model_layer2_0_bn2_running_var: \"f32[128]\", b_model_layer2_0_bn2_num_batches_tracked: \"i64[]\", b_model_layer2_0_shortcut_1_running_mean: \"f32[128]\", b_model_layer2_0_shortcut_1_running_var: \"f32[128]\", b_model_layer2_0_shortcut_1_num_batches_tracked: \"i64[]\", b_model_layer2_1_bn1_running_mean: \"f32[128]\", b_model_layer2_1_bn1_running_var: \"f32[128]\", b_model_layer2_1_bn1_num_batches_tracked: \"i64[]\", b_model_layer2_1_bn2_running_mean: \"f32[128]\", b_model_layer2_1_bn2_running_var: \"f32[128]\", b_model_layer2_1_bn2_num_batches_tracked: \"i64[]\", b_model_layer3_0_bn1_running_mean: \"f32[256]\", b_model_layer3_0_bn1_running_var: \"f32[256]\", b_model_layer3_0_bn1_num_batches_tracked: \"i64[]\", b_model_layer3_0_bn2_running_mean: \"f32[256]\", b_model_layer3_0_bn2_running_var: \"f32[256]\", b_model_layer3_0_bn2_num_batches_tracked: \"i64[]\", b_model_layer3_0_shortcut_1_running_mean: \"f32[256]\", b_model_layer3_0_shortcut_1_running_var: \"f32[256]\", b_model_layer3_0_shortcut_1_num_batches_tracked: \"i64[]\", b_model_layer3_1_bn1_running_mean: \"f32[256]\", b_model_layer3_1_bn1_running_var: \"f32[256]\", b_model_layer3_1_bn1_num_batches_tracked: \"i64[]\", b_model_layer3_1_bn2_running_mean: \"f32[256]\", b_model_layer3_1_bn2_running_var: \"f32[256]\", b_model_layer3_1_bn2_num_batches_tracked: \"i64[]\", x: \"f32[1, 3, 32, 32]\"):\n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d: \"f32[1, 64, 32, 32]\" = torch.ops.aten.conv2d.default(x, p_model_conv1_weight, None, [1, 1], [1, 1]);  x = p_model_conv1_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d, p_model_bn1_weight, p_model_bn1_bias, b_model_bn1_running_mean, b_model_bn1_running_var, 0.1, 1e-05);  conv2d = p_model_bn1_weight = p_model_bn1_bias = b_model_bn1_running_mean = b_model_bn1_running_var = None\n",
       "                    getitem: \"f32[1, 64, 32, 32]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:68 in forward, code: out = F.relu(self.bn1(self.conv1(x)))\n",
       "                    relu: \"f32[1, 64, 32, 32]\" = torch.ops.aten.relu.default(getitem);  getitem = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
       "                    clone: \"f32[1, 64, 32, 32]\" = torch.ops.aten.clone.default(relu);  relu = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_1: \"f32[1, 64, 32, 32]\" = torch.ops.aten.conv2d.default(clone, p_model_layer1_0_conv1_weight, None, [1, 1], [1, 1]);  p_model_layer1_0_conv1_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_1, p_model_layer1_0_bn1_weight, p_model_layer1_0_bn1_bias, b_model_layer1_0_bn1_running_mean, b_model_layer1_0_bn1_running_var, 0.1, 1e-05);  conv2d_1 = p_model_layer1_0_bn1_weight = p_model_layer1_0_bn1_bias = b_model_layer1_0_bn1_running_mean = b_model_layer1_0_bn1_running_var = None\n",
       "                    getitem_3: \"f32[1, 64, 32, 32]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:30 in forward, code: out = F.relu(self.bn1(self.conv1(x)))\n",
       "                    relu_1: \"f32[1, 64, 32, 32]\" = torch.ops.aten.relu.default(getitem_3);  getitem_3 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_2: \"f32[1, 64, 32, 32]\" = torch.ops.aten.conv2d.default(relu_1, p_model_layer1_0_conv2_weight, None, [1, 1], [1, 1]);  relu_1 = p_model_layer1_0_conv2_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_2, p_model_layer1_0_bn2_weight, p_model_layer1_0_bn2_bias, b_model_layer1_0_bn2_running_mean, b_model_layer1_0_bn2_running_var, 0.1, 1e-05);  conv2d_2 = p_model_layer1_0_bn2_weight = p_model_layer1_0_bn2_bias = b_model_layer1_0_bn2_running_mean = b_model_layer1_0_bn2_running_var = None\n",
       "                    getitem_6: \"f32[1, 64, 32, 32]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:32 in forward, code: out += self.shortcut(x)\n",
       "                    add: \"f32[1, 64, 32, 32]\" = torch.ops.aten.add.Tensor(getitem_6, clone);  getitem_6 = clone = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:33 in forward, code: out = F.relu(out)\n",
       "                    relu_2: \"f32[1, 64, 32, 32]\" = torch.ops.aten.relu.default(add);  add = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_3: \"f32[1, 64, 32, 32]\" = torch.ops.aten.conv2d.default(relu_2, p_model_layer1_1_conv1_weight, None, [1, 1], [1, 1]);  p_model_layer1_1_conv1_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, p_model_layer1_1_bn1_weight, p_model_layer1_1_bn1_bias, b_model_layer1_1_bn1_running_mean, b_model_layer1_1_bn1_running_var, 0.1, 1e-05);  conv2d_3 = p_model_layer1_1_bn1_weight = p_model_layer1_1_bn1_bias = b_model_layer1_1_bn1_running_mean = b_model_layer1_1_bn1_running_var = None\n",
       "                    getitem_9: \"f32[1, 64, 32, 32]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:30 in forward, code: out = F.relu(self.bn1(self.conv1(x)))\n",
       "                    relu_3: \"f32[1, 64, 32, 32]\" = torch.ops.aten.relu.default(getitem_9);  getitem_9 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_4: \"f32[1, 64, 32, 32]\" = torch.ops.aten.conv2d.default(relu_3, p_model_layer1_1_conv2_weight, None, [1, 1], [1, 1]);  relu_3 = p_model_layer1_1_conv2_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_4, p_model_layer1_1_bn2_weight, p_model_layer1_1_bn2_bias, b_model_layer1_1_bn2_running_mean, b_model_layer1_1_bn2_running_var, 0.1, 1e-05);  conv2d_4 = p_model_layer1_1_bn2_weight = p_model_layer1_1_bn2_bias = b_model_layer1_1_bn2_running_mean = b_model_layer1_1_bn2_running_var = None\n",
       "                    getitem_12: \"f32[1, 64, 32, 32]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:32 in forward, code: out += self.shortcut(x)\n",
       "                    add_1: \"f32[1, 64, 32, 32]\" = torch.ops.aten.add.Tensor(getitem_12, relu_2);  getitem_12 = relu_2 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:33 in forward, code: out = F.relu(out)\n",
       "                    relu_4: \"f32[1, 64, 32, 32]\" = torch.ops.aten.relu.default(add_1);  add_1 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_5: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(relu_4, p_model_layer2_0_conv1_weight, None, [2, 2], [1, 1]);  p_model_layer2_0_conv1_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_5, p_model_layer2_0_bn1_weight, p_model_layer2_0_bn1_bias, b_model_layer2_0_bn1_running_mean, b_model_layer2_0_bn1_running_var, 0.1, 1e-05);  conv2d_5 = p_model_layer2_0_bn1_weight = p_model_layer2_0_bn1_bias = b_model_layer2_0_bn1_running_mean = b_model_layer2_0_bn1_running_var = None\n",
       "                    getitem_15: \"f32[1, 128, 16, 16]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:30 in forward, code: out = F.relu(self.bn1(self.conv1(x)))\n",
       "                    relu_5: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(getitem_15);  getitem_15 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_6: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(relu_5, p_model_layer2_0_conv2_weight, None, [1, 1], [1, 1]);  relu_5 = p_model_layer2_0_conv2_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_6, p_model_layer2_0_bn2_weight, p_model_layer2_0_bn2_bias, b_model_layer2_0_bn2_running_mean, b_model_layer2_0_bn2_running_var, 0.1, 1e-05);  conv2d_6 = p_model_layer2_0_bn2_weight = p_model_layer2_0_bn2_bias = b_model_layer2_0_bn2_running_mean = b_model_layer2_0_bn2_running_var = None\n",
       "                    getitem_18: \"f32[1, 128, 16, 16]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_7: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(relu_4, p_model_layer2_0_shortcut_0_weight, None, [2, 2]);  relu_4 = p_model_layer2_0_shortcut_0_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_7, p_model_layer2_0_shortcut_1_weight, p_model_layer2_0_shortcut_1_bias, b_model_layer2_0_shortcut_1_running_mean, b_model_layer2_0_shortcut_1_running_var, 0.1, 1e-05);  conv2d_7 = p_model_layer2_0_shortcut_1_weight = p_model_layer2_0_shortcut_1_bias = b_model_layer2_0_shortcut_1_running_mean = b_model_layer2_0_shortcut_1_running_var = None\n",
       "                    getitem_21: \"f32[1, 128, 16, 16]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:32 in forward, code: out += self.shortcut(x)\n",
       "                    add_2: \"f32[1, 128, 16, 16]\" = torch.ops.aten.add.Tensor(getitem_18, getitem_21);  getitem_18 = getitem_21 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:33 in forward, code: out = F.relu(out)\n",
       "                    relu_6: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(add_2);  add_2 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_8: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(relu_6, p_model_layer2_1_conv1_weight, None, [1, 1], [1, 1]);  p_model_layer2_1_conv1_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_8, p_model_layer2_1_bn1_weight, p_model_layer2_1_bn1_bias, b_model_layer2_1_bn1_running_mean, b_model_layer2_1_bn1_running_var, 0.1, 1e-05);  conv2d_8 = p_model_layer2_1_bn1_weight = p_model_layer2_1_bn1_bias = b_model_layer2_1_bn1_running_mean = b_model_layer2_1_bn1_running_var = None\n",
       "                    getitem_24: \"f32[1, 128, 16, 16]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:30 in forward, code: out = F.relu(self.bn1(self.conv1(x)))\n",
       "                    relu_7: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(getitem_24);  getitem_24 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_9: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(relu_7, p_model_layer2_1_conv2_weight, None, [1, 1], [1, 1]);  relu_7 = p_model_layer2_1_conv2_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_9, p_model_layer2_1_bn2_weight, p_model_layer2_1_bn2_bias, b_model_layer2_1_bn2_running_mean, b_model_layer2_1_bn2_running_var, 0.1, 1e-05);  conv2d_9 = p_model_layer2_1_bn2_weight = p_model_layer2_1_bn2_bias = b_model_layer2_1_bn2_running_mean = b_model_layer2_1_bn2_running_var = None\n",
       "                    getitem_27: \"f32[1, 128, 16, 16]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:32 in forward, code: out += self.shortcut(x)\n",
       "                    add_3: \"f32[1, 128, 16, 16]\" = torch.ops.aten.add.Tensor(getitem_27, relu_6);  getitem_27 = relu_6 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:33 in forward, code: out = F.relu(out)\n",
       "                    relu_8: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(add_3);  add_3 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_10: \"f32[1, 256, 8, 8]\" = torch.ops.aten.conv2d.default(relu_8, p_model_layer3_0_conv1_weight, None, [2, 2], [1, 1]);  p_model_layer3_0_conv1_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_10, p_model_layer3_0_bn1_weight, p_model_layer3_0_bn1_bias, b_model_layer3_0_bn1_running_mean, b_model_layer3_0_bn1_running_var, 0.1, 1e-05);  conv2d_10 = p_model_layer3_0_bn1_weight = p_model_layer3_0_bn1_bias = b_model_layer3_0_bn1_running_mean = b_model_layer3_0_bn1_running_var = None\n",
       "                    getitem_30: \"f32[1, 256, 8, 8]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:30 in forward, code: out = F.relu(self.bn1(self.conv1(x)))\n",
       "                    relu_9: \"f32[1, 256, 8, 8]\" = torch.ops.aten.relu.default(getitem_30);  getitem_30 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_11: \"f32[1, 256, 8, 8]\" = torch.ops.aten.conv2d.default(relu_9, p_model_layer3_0_conv2_weight, None, [1, 1], [1, 1]);  relu_9 = p_model_layer3_0_conv2_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_11, p_model_layer3_0_bn2_weight, p_model_layer3_0_bn2_bias, b_model_layer3_0_bn2_running_mean, b_model_layer3_0_bn2_running_var, 0.1, 1e-05);  conv2d_11 = p_model_layer3_0_bn2_weight = p_model_layer3_0_bn2_bias = b_model_layer3_0_bn2_running_mean = b_model_layer3_0_bn2_running_var = None\n",
       "                    getitem_33: \"f32[1, 256, 8, 8]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_12: \"f32[1, 256, 8, 8]\" = torch.ops.aten.conv2d.default(relu_8, p_model_layer3_0_shortcut_0_weight, None, [2, 2]);  relu_8 = p_model_layer3_0_shortcut_0_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_12, p_model_layer3_0_shortcut_1_weight, p_model_layer3_0_shortcut_1_bias, b_model_layer3_0_shortcut_1_running_mean, b_model_layer3_0_shortcut_1_running_var, 0.1, 1e-05);  conv2d_12 = p_model_layer3_0_shortcut_1_weight = p_model_layer3_0_shortcut_1_bias = b_model_layer3_0_shortcut_1_running_mean = b_model_layer3_0_shortcut_1_running_var = None\n",
       "                    getitem_36: \"f32[1, 256, 8, 8]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:32 in forward, code: out += self.shortcut(x)\n",
       "                    add_4: \"f32[1, 256, 8, 8]\" = torch.ops.aten.add.Tensor(getitem_33, getitem_36);  getitem_33 = getitem_36 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:33 in forward, code: out = F.relu(out)\n",
       "                    relu_10: \"f32[1, 256, 8, 8]\" = torch.ops.aten.relu.default(add_4);  add_4 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_13: \"f32[1, 256, 8, 8]\" = torch.ops.aten.conv2d.default(relu_10, p_model_layer3_1_conv1_weight, None, [1, 1], [1, 1]);  p_model_layer3_1_conv1_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_13, p_model_layer3_1_bn1_weight, p_model_layer3_1_bn1_bias, b_model_layer3_1_bn1_running_mean, b_model_layer3_1_bn1_running_var, 0.1, 1e-05);  conv2d_13 = p_model_layer3_1_bn1_weight = p_model_layer3_1_bn1_bias = b_model_layer3_1_bn1_running_mean = b_model_layer3_1_bn1_running_var = None\n",
       "                    getitem_39: \"f32[1, 256, 8, 8]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:30 in forward, code: out = F.relu(self.bn1(self.conv1(x)))\n",
       "                    relu_11: \"f32[1, 256, 8, 8]\" = torch.ops.aten.relu.default(getitem_39);  getitem_39 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_14: \"f32[1, 256, 8, 8]\" = torch.ops.aten.conv2d.default(relu_11, p_model_layer3_1_conv2_weight, None, [1, 1], [1, 1]);  relu_11 = p_model_layer3_1_conv2_weight = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_14, p_model_layer3_1_bn2_weight, p_model_layer3_1_bn2_bias, b_model_layer3_1_bn2_running_mean, b_model_layer3_1_bn2_running_var, 0.1, 1e-05);  conv2d_14 = p_model_layer3_1_bn2_weight = p_model_layer3_1_bn2_bias = b_model_layer3_1_bn2_running_mean = b_model_layer3_1_bn2_running_var = None\n",
       "                    getitem_42: \"f32[1, 256, 8, 8]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:32 in forward, code: out += self.shortcut(x)\n",
       "                    add_5: \"f32[1, 256, 8, 8]\" = torch.ops.aten.add.Tensor(getitem_42, relu_10);  getitem_42 = relu_10 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:33 in forward, code: out = F.relu(out)\n",
       "                    relu_12: \"f32[1, 256, 8, 8]\" = torch.ops.aten.relu.default(add_5);  add_5 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean: \"f32[1, 256, 1, 1]\" = torch.ops.aten.mean.dim(relu_12, [-1, -2], True);  relu_12 = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/coding/kretsinger/kret_lightning/examples/cifar10_module.py:74 in forward, code: out = out.view(out.size(0), -1)\n",
       "                    view: \"f32[1, 256]\" = torch.ops.aten.view.default(mean, [1, -1]);  mean = None\n",
       "            \n",
       "                     # File: /Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, 10]\" = torch.ops.aten.linear.default(view, p_model_fc_weight, p_model_fc_bias);  view = p_model_fc_weight = p_model_fc_bias = None\n",
       "                    return (linear,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_model_conv1_weight: PARAMETER target='model.conv1.weight'\n",
       "            p_model_bn1_weight: PARAMETER target='model.bn1.weight'\n",
       "            p_model_bn1_bias: PARAMETER target='model.bn1.bias'\n",
       "            p_model_layer1_0_conv1_weight: PARAMETER target='model.layer1.0.conv1.weight'\n",
       "            p_model_layer1_0_bn1_weight: PARAMETER target='model.layer1.0.bn1.weight'\n",
       "            p_model_layer1_0_bn1_bias: PARAMETER target='model.layer1.0.bn1.bias'\n",
       "            p_model_layer1_0_conv2_weight: PARAMETER target='model.layer1.0.conv2.weight'\n",
       "            p_model_layer1_0_bn2_weight: PARAMETER target='model.layer1.0.bn2.weight'\n",
       "            p_model_layer1_0_bn2_bias: PARAMETER target='model.layer1.0.bn2.bias'\n",
       "            p_model_layer1_1_conv1_weight: PARAMETER target='model.layer1.1.conv1.weight'\n",
       "            p_model_layer1_1_bn1_weight: PARAMETER target='model.layer1.1.bn1.weight'\n",
       "            p_model_layer1_1_bn1_bias: PARAMETER target='model.layer1.1.bn1.bias'\n",
       "            p_model_layer1_1_conv2_weight: PARAMETER target='model.layer1.1.conv2.weight'\n",
       "            p_model_layer1_1_bn2_weight: PARAMETER target='model.layer1.1.bn2.weight'\n",
       "            p_model_layer1_1_bn2_bias: PARAMETER target='model.layer1.1.bn2.bias'\n",
       "            p_model_layer2_0_conv1_weight: PARAMETER target='model.layer2.0.conv1.weight'\n",
       "            p_model_layer2_0_bn1_weight: PARAMETER target='model.layer2.0.bn1.weight'\n",
       "            p_model_layer2_0_bn1_bias: PARAMETER target='model.layer2.0.bn1.bias'\n",
       "            p_model_layer2_0_conv2_weight: PARAMETER target='model.layer2.0.conv2.weight'\n",
       "            p_model_layer2_0_bn2_weight: PARAMETER target='model.layer2.0.bn2.weight'\n",
       "            p_model_layer2_0_bn2_bias: PARAMETER target='model.layer2.0.bn2.bias'\n",
       "            p_model_layer2_0_shortcut_0_weight: PARAMETER target='model.layer2.0.shortcut.0.weight'\n",
       "            p_model_layer2_0_shortcut_1_weight: PARAMETER target='model.layer2.0.shortcut.1.weight'\n",
       "            p_model_layer2_0_shortcut_1_bias: PARAMETER target='model.layer2.0.shortcut.1.bias'\n",
       "            p_model_layer2_1_conv1_weight: PARAMETER target='model.layer2.1.conv1.weight'\n",
       "            p_model_layer2_1_bn1_weight: PARAMETER target='model.layer2.1.bn1.weight'\n",
       "            p_model_layer2_1_bn1_bias: PARAMETER target='model.layer2.1.bn1.bias'\n",
       "            p_model_layer2_1_conv2_weight: PARAMETER target='model.layer2.1.conv2.weight'\n",
       "            p_model_layer2_1_bn2_weight: PARAMETER target='model.layer2.1.bn2.weight'\n",
       "            p_model_layer2_1_bn2_bias: PARAMETER target='model.layer2.1.bn2.bias'\n",
       "            p_model_layer3_0_conv1_weight: PARAMETER target='model.layer3.0.conv1.weight'\n",
       "            p_model_layer3_0_bn1_weight: PARAMETER target='model.layer3.0.bn1.weight'\n",
       "            p_model_layer3_0_bn1_bias: PARAMETER target='model.layer3.0.bn1.bias'\n",
       "            p_model_layer3_0_conv2_weight: PARAMETER target='model.layer3.0.conv2.weight'\n",
       "            p_model_layer3_0_bn2_weight: PARAMETER target='model.layer3.0.bn2.weight'\n",
       "            p_model_layer3_0_bn2_bias: PARAMETER target='model.layer3.0.bn2.bias'\n",
       "            p_model_layer3_0_shortcut_0_weight: PARAMETER target='model.layer3.0.shortcut.0.weight'\n",
       "            p_model_layer3_0_shortcut_1_weight: PARAMETER target='model.layer3.0.shortcut.1.weight'\n",
       "            p_model_layer3_0_shortcut_1_bias: PARAMETER target='model.layer3.0.shortcut.1.bias'\n",
       "            p_model_layer3_1_conv1_weight: PARAMETER target='model.layer3.1.conv1.weight'\n",
       "            p_model_layer3_1_bn1_weight: PARAMETER target='model.layer3.1.bn1.weight'\n",
       "            p_model_layer3_1_bn1_bias: PARAMETER target='model.layer3.1.bn1.bias'\n",
       "            p_model_layer3_1_conv2_weight: PARAMETER target='model.layer3.1.conv2.weight'\n",
       "            p_model_layer3_1_bn2_weight: PARAMETER target='model.layer3.1.bn2.weight'\n",
       "            p_model_layer3_1_bn2_bias: PARAMETER target='model.layer3.1.bn2.bias'\n",
       "            p_model_fc_weight: PARAMETER target='model.fc.weight'\n",
       "            p_model_fc_bias: PARAMETER target='model.fc.bias'\n",
       "            b_model_bn1_running_mean: BUFFER target='model.bn1.running_mean' persistent=True\n",
       "            b_model_bn1_running_var: BUFFER target='model.bn1.running_var' persistent=True\n",
       "            b_model_bn1_num_batches_tracked: BUFFER target='model.bn1.num_batches_tracked' persistent=True\n",
       "            b_model_layer1_0_bn1_running_mean: BUFFER target='model.layer1.0.bn1.running_mean' persistent=True\n",
       "            b_model_layer1_0_bn1_running_var: BUFFER target='model.layer1.0.bn1.running_var' persistent=True\n",
       "            b_model_layer1_0_bn1_num_batches_tracked: BUFFER target='model.layer1.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_model_layer1_0_bn2_running_mean: BUFFER target='model.layer1.0.bn2.running_mean' persistent=True\n",
       "            b_model_layer1_0_bn2_running_var: BUFFER target='model.layer1.0.bn2.running_var' persistent=True\n",
       "            b_model_layer1_0_bn2_num_batches_tracked: BUFFER target='model.layer1.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_model_layer1_1_bn1_running_mean: BUFFER target='model.layer1.1.bn1.running_mean' persistent=True\n",
       "            b_model_layer1_1_bn1_running_var: BUFFER target='model.layer1.1.bn1.running_var' persistent=True\n",
       "            b_model_layer1_1_bn1_num_batches_tracked: BUFFER target='model.layer1.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_model_layer1_1_bn2_running_mean: BUFFER target='model.layer1.1.bn2.running_mean' persistent=True\n",
       "            b_model_layer1_1_bn2_running_var: BUFFER target='model.layer1.1.bn2.running_var' persistent=True\n",
       "            b_model_layer1_1_bn2_num_batches_tracked: BUFFER target='model.layer1.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_model_layer2_0_bn1_running_mean: BUFFER target='model.layer2.0.bn1.running_mean' persistent=True\n",
       "            b_model_layer2_0_bn1_running_var: BUFFER target='model.layer2.0.bn1.running_var' persistent=True\n",
       "            b_model_layer2_0_bn1_num_batches_tracked: BUFFER target='model.layer2.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_model_layer2_0_bn2_running_mean: BUFFER target='model.layer2.0.bn2.running_mean' persistent=True\n",
       "            b_model_layer2_0_bn2_running_var: BUFFER target='model.layer2.0.bn2.running_var' persistent=True\n",
       "            b_model_layer2_0_bn2_num_batches_tracked: BUFFER target='model.layer2.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_model_layer2_0_shortcut_1_running_mean: BUFFER target='model.layer2.0.shortcut.1.running_mean' persistent=True\n",
       "            b_model_layer2_0_shortcut_1_running_var: BUFFER target='model.layer2.0.shortcut.1.running_var' persistent=True\n",
       "            b_model_layer2_0_shortcut_1_num_batches_tracked: BUFFER target='model.layer2.0.shortcut.1.num_batches_tracked' persistent=True\n",
       "            b_model_layer2_1_bn1_running_mean: BUFFER target='model.layer2.1.bn1.running_mean' persistent=True\n",
       "            b_model_layer2_1_bn1_running_var: BUFFER target='model.layer2.1.bn1.running_var' persistent=True\n",
       "            b_model_layer2_1_bn1_num_batches_tracked: BUFFER target='model.layer2.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_model_layer2_1_bn2_running_mean: BUFFER target='model.layer2.1.bn2.running_mean' persistent=True\n",
       "            b_model_layer2_1_bn2_running_var: BUFFER target='model.layer2.1.bn2.running_var' persistent=True\n",
       "            b_model_layer2_1_bn2_num_batches_tracked: BUFFER target='model.layer2.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_model_layer3_0_bn1_running_mean: BUFFER target='model.layer3.0.bn1.running_mean' persistent=True\n",
       "            b_model_layer3_0_bn1_running_var: BUFFER target='model.layer3.0.bn1.running_var' persistent=True\n",
       "            b_model_layer3_0_bn1_num_batches_tracked: BUFFER target='model.layer3.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_model_layer3_0_bn2_running_mean: BUFFER target='model.layer3.0.bn2.running_mean' persistent=True\n",
       "            b_model_layer3_0_bn2_running_var: BUFFER target='model.layer3.0.bn2.running_var' persistent=True\n",
       "            b_model_layer3_0_bn2_num_batches_tracked: BUFFER target='model.layer3.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_model_layer3_0_shortcut_1_running_mean: BUFFER target='model.layer3.0.shortcut.1.running_mean' persistent=True\n",
       "            b_model_layer3_0_shortcut_1_running_var: BUFFER target='model.layer3.0.shortcut.1.running_var' persistent=True\n",
       "            b_model_layer3_0_shortcut_1_num_batches_tracked: BUFFER target='model.layer3.0.shortcut.1.num_batches_tracked' persistent=True\n",
       "            b_model_layer3_1_bn1_running_mean: BUFFER target='model.layer3.1.bn1.running_mean' persistent=True\n",
       "            b_model_layer3_1_bn1_running_var: BUFFER target='model.layer3.1.bn1.running_var' persistent=True\n",
       "            b_model_layer3_1_bn1_num_batches_tracked: BUFFER target='model.layer3.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_model_layer3_1_bn2_running_mean: BUFFER target='model.layer3.1.bn2.running_mean' persistent=True\n",
       "            b_model_layer3_1_bn2_running_var: BUFFER target='model.layer3.1.bn2.running_var' persistent=True\n",
       "            b_model_layer3_1_bn2_num_batches_tracked: BUFFER target='model.layer3.1.bn2.num_batches_tracked' persistent=True\n",
       "            x: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            linear: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_nn.eval().to(\"cpu\")\n",
    "# raise ValueError(\"STOP\")\n",
    "dummy_input = torch.randn(1, 3, 32, 32)  # adjust shape to your model\n",
    "\n",
    "torch.onnx.export(\n",
    "    cifar_nn,\n",
    "    dummy_input,\n",
    "    UKS_CONSTANTS.TORCH_MODEL_VIZ_DIR / f\"{cifar_nn.name}.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=20,\n",
    "    do_constant_folding=True,\n",
    "    # input_names=[\"input\"],\n",
    "    # output_names=[\"output\"],\n",
    "    # dynamic_axes={\n",
    "    #     \"input\": {0: \"batch_size\"},\n",
    "    #     \"output\": {0: \"batch_size\"},\n",
    "    # },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kret_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
