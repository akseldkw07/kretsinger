{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from /Users/Akseldkw/coding/kretsinger/.env\n",
      "[kret_matplotlib.mpl_nb_imports] Imported kret_matplotlib.mpl_nb_imports in 2.0006 seconds\n",
      "[kret_np_pd.np_pd_nb_imports] Imported kret_np_pd.np_pd_nb_imports in 1.1344 seconds\n",
      "[kret_sklearn.sklearn_nb_imports] Imported kret_sklearn.sklearn_nb_imports in 0.5408 seconds\n",
      "[kret_torch_utils.torch_nb_imports] Imported kret_torch_utils.torch_nb_imports in 2.5645 seconds\n",
      "[kret_lightning.lightning_nb_imports] Imported kret_lightning.lightning_nb_imports in 0.1031 seconds\n",
      "[kret_tqdm.tqdm_nb_imports] Imported kret_tqdm.tqdm_nb_imports in 0.0000 seconds\n",
      "[kret_type_hints.types_nb_imports] Imported kret_type_hints.types_nb_imports in 0.0003 seconds\n",
      "[kret_utils.utils_nb_imports] Imported kret_utils.utils_nb_imports in 0.0002 seconds\n"
     ]
    }
   ],
   "source": [
    "from kret_notebook import *  # NOTE import first\n",
    "from kret_matplotlib.mpl_nb_imports import *\n",
    "from kret_np_pd.np_pd_nb_imports import *\n",
    "from kret_sklearn.sklearn_nb_imports import *\n",
    "from kret_torch_utils.torch_nb_imports import *\n",
    "from kret_lightning.lightning_nb_imports import *\n",
    "from kret_tqdm.tqdm_nb_imports import *\n",
    "from kret_type_hints.types_nb_imports import *\n",
    "from kret_utils.utils_nb_imports import *\n",
    "\n",
    "# from kret_wandb.wandb_nb_imports import *  # NOTE this is slow to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_data import MNISTDataModule\n",
    "\n",
    "mnist_data_module = MNISTDataModule(DATA_DIR / \"MNIST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kret_lightning.abc_lightning import HPasKwargs\n",
    "\n",
    "\n",
    "class Kret_AutoEncoder(BaseLightningNN):\n",
    "    _criterion: nn.Module = nn.MSELoss()\n",
    "\n",
    "    def __init__(self, embedding_dim: tuple[int, int], **kwargs: t.Unpack[HPasKwargs]):\n",
    "        super().__init__(**kwargs)\n",
    "        # define any number of nn.Modules (or use your current ones)\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(*embedding_dim))\n",
    "        self.decoder = nn.Sequential(nn.Linear(embedding_dim[1], embedding_dim[0]), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # print(f\"Input shape: {x.shape}\")\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    # endregion\n",
    "    # region Training / Validation Steps\n",
    "    def training_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        loss = ...\n",
    "        return loss\n",
    "        \"\"\"\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        outputs = self(x)\n",
    "        loss = self.get_loss(outputs, x)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> None:\n",
    "        \"\"\"\n",
    "        val_loss = ...\n",
    "        self.log('val_loss', val_loss)\n",
    "        \"\"\"\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        outputs = self(x)\n",
    "        val_loss = self.get_loss(outputs, x)\n",
    "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    # endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Kret_AutoEncoder((64, 3))\n",
    "auto_enc = base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'save_dir': PosixPath('/Users/Akseldkw/coding/data_kretsinger/lightning_logs'),\n",
       " 'name': 'Kret_AutoEncoder',\n",
       " 'version': 'v_000'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.save_load_logging_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CSVLogger(**base.save_load_logging_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_args = TrainerStaticDefaults.TRAINER_QUICK_ITER\n",
    "dynamic_args = TrainerDynamicDefaults.trainer_dynamic_defaults(auto_enc, mnist_data_module)\n",
    "trainer_args = static_args | dynamic_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_epochs': 5,\n",
       " 'max_epochs': 5,\n",
       " 'check_val_every_n_epoch': 1,\n",
       " 'log_every_n_steps': 10,\n",
       " 'limit_train_batches': 0.1,\n",
       " 'limit_val_batches': 0.1,\n",
       " 'limit_test_batches': 0.1,\n",
       " 'logger': <lightning.pytorch.loggers.csv_logs.CSVLogger at 0x16cc06720>,\n",
       " 'callbacks': [<lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint at 0x3056526c0>],\n",
       " 'default_root_dir': PosixPath('/Users/Akseldkw/coding/data_kretsinger/lightning_logs/Kret_AutoEncoder/v_000')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/Akseldkw/coding/data_kretsinger/lightning_logs',\n",
       " lightning.pytorch.loggers.csv_logs.CSVLogger)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = trainer_args[\"logger\"]\n",
    "logger._save_dir, type(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(**trainer_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Stop here",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mStop here\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Stop here"
     ]
    }
   ],
   "source": [
    "raise ValueError(\"Stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ encoder │ Sequential │ 50.4 K │ train │     0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ decoder │ Sequential │ 51.2 K │ train │     0 │\n",
       "└───┴─────────┴────────────┴────────┴───────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ encoder │ Sequential │ 50.4 K │ train │     0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ decoder │ Sequential │ 51.2 K │ train │     0 │\n",
       "└───┴─────────┴────────────┴────────┴───────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 101 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 101 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 8                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 101 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 101 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 8                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68321023883f43f2a2ce70b26e57e42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_con\n",
       "nector.py:485: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn \n",
       "shuffling off for val/test dataloaders.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_con\n",
       "nector.py:485: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn \n",
       "shuffling off for val/test dataloaders.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 86: 'val_loss' reached 0.61594 (best 0.61594), saving model to '/Users/Akseldkw/coding/data_kretsinger/lightning_logs/Kret_AutoEncoder/v_000/checkpoints/best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 172: 'val_loss' reached 0.53020 (best 0.53020), saving model to '/Users/Akseldkw/coding/data_kretsinger/lightning_logs/Kret_AutoEncoder/v_000/checkpoints/best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 258: 'val_loss' reached 0.52180 (best 0.52180), saving model to '/Users/Akseldkw/coding/data_kretsinger/lightning_logs/Kret_AutoEncoder/v_000/checkpoints/best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 344: 'val_loss' reached 0.50724 (best 0.50724), saving model to '/Users/Akseldkw/coding/data_kretsinger/lightning_logs/Kret_AutoEncoder/v_000/checkpoints/best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 430: 'val_loss' reached 0.48235 (best 0.48235), saving model to '/Users/Akseldkw/coding/data_kretsinger/lightning_logs/Kret_AutoEncoder/v_000/checkpoints/best.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=auto_enc, datamodule=mnist_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kret_AutoEncoder'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_enc.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/Akseldkw/coding/data_kretsinger/lightning_logs/Kret_AutoEncoder/v_000/checkpoints/best.ckpt')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = Kret_AutoEncoder.ckpt_file_name()\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_enc_saved = Kret_AutoEncoder.load_from_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"embedding_dim\": (64, 3)\n",
       "\"gamma\":         0.5\n",
       "\"l1_penalty\":    0.0\n",
       "\"l2_penalty\":    0.0\n",
       "\"lr\":            0.001\n",
       "\"patience\":      10\n",
       "\"stepsize\":      12"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_enc_saved.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"embedding_dim\": (64, 3)\n",
       "\"gamma\":         0.5\n",
       "\"l1_penalty\":    0.0\n",
       "\"l2_penalty\":    0.0\n",
       "\"lr\":            0.001\n",
       "\"patience\":      10\n",
       "\"stepsize\":      12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_enc_saved.hparams_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kret_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
