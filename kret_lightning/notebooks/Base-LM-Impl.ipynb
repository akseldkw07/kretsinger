{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from /Users/Akseldkw/coding/kretsinger/.env\n",
      "[kret_matplotlib.mpl_nb_imports] Imported kret_matplotlib.mpl_nb_imports in 1.5523 seconds\n",
      "[kret_np_pd.np_pd_nb_imports] Imported kret_np_pd.np_pd_nb_imports in 0.8158 seconds\n",
      "[kret_sklearn.sklearn_nb_imports] Imported kret_sklearn.sklearn_nb_imports in 0.4022 seconds\n",
      "[kret_torch_utils.torch_nb_imports] Imported kret_torch_utils.torch_nb_imports in 2.0053 seconds\n",
      "[kret_lightning.lightning_nb_imports] Imported kret_lightning.lightning_nb_imports in 0.0596 seconds\n",
      "[kret_tqdm.tqdm_nb_imports] Imported kret_tqdm.tqdm_nb_imports in 0.0000 seconds\n",
      "[kret_type_hints.types_nb_imports] Imported kret_type_hints.types_nb_imports in 0.0003 seconds\n",
      "[kret_utils.utils_nb_imports] Imported kret_utils.utils_nb_imports in 0.0002 seconds\n"
     ]
    }
   ],
   "source": [
    "from kret_notebook import *  # NOTE import first\n",
    "from kret_matplotlib.mpl_nb_imports import *\n",
    "from kret_np_pd.np_pd_nb_imports import *\n",
    "from kret_sklearn.sklearn_nb_imports import *\n",
    "from kret_torch_utils.torch_nb_imports import *\n",
    "from kret_lightning.lightning_nb_imports import *\n",
    "from kret_tqdm.tqdm_nb_imports import *\n",
    "from kret_type_hints.types_nb_imports import *\n",
    "from kret_utils.utils_nb_imports import *\n",
    "\n",
    "# from kret_wandb.wandb_nb_imports import *  # NOTE this is slow to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_data import MNISTDataModule\n",
    "\n",
    "mnist_data_module = MNISTDataModule(DATA_DIR / \"MNIST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kret_lightning.base_lightning_nn import HPasKwargs\n",
    "\n",
    "\n",
    "class ExLNN(BaseLightningNN):\n",
    "    _criterion: nn.Module = nn.MSELoss()\n",
    "\n",
    "    def __init__(self, embedding_dim: tuple[int, int], **kwargs: t.Unpack[HPasKwargs]):\n",
    "        super().__init__(**kwargs)\n",
    "        # define any number of nn.Modules (or use your current ones)\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(*embedding_dim))\n",
    "        self.decoder = nn.Sequential(nn.Linear(embedding_dim[1], embedding_dim[0]), nn.ReLU(), nn.Linear(64, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = ExLNN((64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"embedding_dim\": (64, 3)\n",
       "\"gamma\":         0.5\n",
       "\"l1_lambda\":     0.0\n",
       "\"l2_lambda\":     0.0\n",
       "\"lr\":            0.001\n",
       "\"stepsize\":      12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     decoupled_weight_decay: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     initial_lr: 0.001\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'lr_scheduler': <torch.optim.lr_scheduler.StepLR at 0x176722420>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.configure_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import CSVLogger, WandbLogger, TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kret_sandbox.func_to_typed_dict import FuncToTypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testfunc(\n",
    "    a: int,\n",
    "    b: str | None = \"default\",\n",
    "    c: t.Literal[\"a\", \"b\", \"c\"] | bool = False,\n",
    "    mylist: list[t.Literal[0, 1]] = [0],\n",
    ") -> None:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import t.Literal\n",
      "class Testfunc_TypedDict(t.TypedDict, total=False):\n",
      "    a: int\n",
      "    b: str | None\n",
      "    c: t.Literal['a' | 'b' | 'c'] | bool\n",
      "    mylist: list[t.Literal[0 | 1]]\n"
     ]
    }
   ],
   "source": [
    "UKS_TH_UTILS.func_to_typed_dict(testfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Config(TypedDict):\n",
      "    a: int\n",
      "    b: UnionType[str, None]\n",
      "    c: Literal[a, b, c] | bool\n",
      "    mylist: list[Literal[0, 1]]\n",
      "    return: None\n"
     ]
    }
   ],
   "source": [
    "FuncToTypedDict.func_to_typed_dict(testfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "\n",
    "\n",
    "class Testfunc_TypedDict(t.TypedDict, total=False):\n",
    "    a: int\n",
    "    b: str | None\n",
    "    c: t.Literal[\"a\", \"b\", \"c\"] | bool  # TODO Had to fix\n",
    "    mylist: list[t.Literal[0, 1]]  # TODO Had to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import collections.abc.Iterable\n",
      "import datetime.timedelta\n",
      "import lightning.fabric.plugins.environments.cluster_environment.ClusterEnvironment\n",
      "import lightning.fabric.plugins.io.checkpoint_io.CheckpointIO\n",
      "import lightning.pytorch.accelerators.accelerator.Accelerator\n",
      "import lightning.pytorch.callbacks.callback.Callback\n",
      "import lightning.pytorch.loggers.logger.Logger\n",
      "import lightning.pytorch.plugins.layer_sync.LayerSync\n",
      "import lightning.pytorch.plugins.precision.precision.Precision\n",
      "import lightning.pytorch.profilers.profiler.Profiler\n",
      "import lightning.pytorch.strategies.strategy.Strategy\n",
      "import pathlib.Path\n",
      "import t.Any\n",
      "import t.Literal\n",
      "class __init___TypedDict(t.TypedDict, total=False):\n",
      "    self: t.Any\n",
      "    accelerator: str | lightning.pytorch.accelerators.accelerator.Accelerator\n",
      "    strategy: str | lightning.pytorch.strategies.strategy.Strategy\n",
      "    devices: list[int] | str | int\n",
      "    num_nodes: int\n",
      "    precision: t.Literal[64 | 32 | 16] | t.Literal['transformer-engine' | 'transformer-engine-float16' | '16-true' | '16-mixed' | 'bf16-true' | 'bf16-mixed' | '32-true' | '64-true'] | t.Literal['64' | '32' | '16' | 'bf16'] | None\n",
      "    logger: lightning.pytorch.loggers.logger.Logger | collections.abc.Iterable[lightning.pytorch.loggers.logger.Logger] | bool | None\n",
      "    callbacks: list[lightning.pytorch.callbacks.callback.Callback] | lightning.pytorch.callbacks.callback.Callback | None\n",
      "    fast_dev_run: int | bool\n",
      "    max_epochs: int | None\n",
      "    min_epochs: int | None\n",
      "    max_steps: int\n",
      "    min_steps: int | None\n",
      "    max_time: str | datetime.timedelta | dict[str | int] | None\n",
      "    limit_train_batches: float | int | None\n",
      "    limit_val_batches: float | int | None\n",
      "    limit_test_batches: float | int | None\n",
      "    limit_predict_batches: float | int | None\n",
      "    overfit_batches: int | float\n",
      "    val_check_interval: int | float | str | datetime.timedelta | dict[str | int] | None\n",
      "    check_val_every_n_epoch: int | None\n",
      "    num_sanity_val_steps: int | None\n",
      "    log_every_n_steps: int | None\n",
      "    enable_checkpointing: bool | None\n",
      "    enable_progress_bar: bool | None\n",
      "    enable_model_summary: bool | None\n",
      "    accumulate_grad_batches: int\n",
      "    gradient_clip_val: float | int | None\n",
      "    gradient_clip_algorithm: str | None\n",
      "    deterministic: bool | t.Literal['warn'] | None\n",
      "    benchmark: bool | None\n",
      "    inference_mode: bool\n",
      "    use_distributed_sampler: bool\n",
      "    profiler: lightning.pytorch.profilers.profiler.Profiler | str | None\n",
      "    detect_anomaly: bool\n",
      "    barebones: bool\n",
      "    plugins: lightning.pytorch.plugins.precision.precision.Precision | lightning.fabric.plugins.environments.cluster_environment.ClusterEnvironment | lightning.fabric.plugins.io.checkpoint_io.CheckpointIO | lightning.pytorch.plugins.layer_sync.LayerSync | list[lightning.pytorch.plugins.precision.precision.Precision | lightning.pytorch.plugins.layer_sync.LayerSync] | None\n",
      "    sync_batchnorm: bool\n",
      "    reload_dataloaders_every_n_epochs: int\n",
      "    default_root_dir: str | pathlib.Path | None\n",
      "    enable_autolog_hparams: bool\n",
      "    model_registry: str | None\n"
     ]
    }
   ],
   "source": [
    "UKS_TH_UTILS.func_to_typed_dict(L.Trainer.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accelerator': typing.Union[str, lightning.pytorch.accelerators.accelerator.Accelerator],\n",
       " 'strategy': typing.Union[str, lightning.pytorch.strategies.strategy.Strategy],\n",
       " 'devices': typing.Union[list[int], str, int],\n",
       " 'num_nodes': int,\n",
       " 'precision': typing.Union[typing.Literal[64, 32, 16], typing.Literal['transformer-engine', 'transformer-engine-float16', '16-true', '16-mixed', 'bf16-true', 'bf16-mixed', '32-true', '64-true'], typing.Literal['64', '32', '16', 'bf16'], NoneType],\n",
       " 'logger': typing.Union[lightning.pytorch.loggers.logger.Logger, collections.abc.Iterable[lightning.pytorch.loggers.logger.Logger], bool, NoneType],\n",
       " 'callbacks': typing.Union[list[lightning.pytorch.callbacks.callback.Callback], lightning.pytorch.callbacks.callback.Callback, NoneType],\n",
       " 'fast_dev_run': typing.Union[int, bool],\n",
       " 'max_epochs': typing.Optional[int],\n",
       " 'min_epochs': typing.Optional[int],\n",
       " 'max_steps': int,\n",
       " 'min_steps': typing.Optional[int],\n",
       " 'max_time': typing.Union[str, datetime.timedelta, dict[str, int], NoneType],\n",
       " 'limit_train_batches': typing.Union[float, int, NoneType],\n",
       " 'limit_val_batches': typing.Union[float, int, NoneType],\n",
       " 'limit_test_batches': typing.Union[float, int, NoneType],\n",
       " 'limit_predict_batches': typing.Union[float, int, NoneType],\n",
       " 'overfit_batches': typing.Union[int, float],\n",
       " 'val_check_interval': typing.Union[int, float, str, datetime.timedelta, dict[str, int], NoneType],\n",
       " 'check_val_every_n_epoch': typing.Optional[int],\n",
       " 'num_sanity_val_steps': typing.Optional[int],\n",
       " 'log_every_n_steps': typing.Optional[int],\n",
       " 'enable_checkpointing': typing.Optional[bool],\n",
       " 'enable_progress_bar': typing.Optional[bool],\n",
       " 'enable_model_summary': typing.Optional[bool],\n",
       " 'accumulate_grad_batches': int,\n",
       " 'gradient_clip_val': typing.Union[float, int, NoneType],\n",
       " 'gradient_clip_algorithm': typing.Optional[str],\n",
       " 'deterministic': typing.Union[bool, typing.Literal['warn'], NoneType],\n",
       " 'benchmark': typing.Optional[bool],\n",
       " 'inference_mode': bool,\n",
       " 'use_distributed_sampler': bool,\n",
       " 'profiler': typing.Union[lightning.pytorch.profilers.profiler.Profiler, str, NoneType],\n",
       " 'detect_anomaly': bool,\n",
       " 'barebones': bool,\n",
       " 'plugins': typing.Union[lightning.pytorch.plugins.precision.precision.Precision, lightning.fabric.plugins.environments.cluster_environment.ClusterEnvironment, lightning.fabric.plugins.io.checkpoint_io.CheckpointIO, lightning.pytorch.plugins.layer_sync.LayerSync, list[typing.Union[lightning.pytorch.plugins.precision.precision.Precision, lightning.fabric.plugins.environments.cluster_environment.ClusterEnvironment, lightning.fabric.plugins.io.checkpoint_io.CheckpointIO, lightning.pytorch.plugins.layer_sync.LayerSync]], NoneType],\n",
       " 'sync_batchnorm': bool,\n",
       " 'reload_dataloaders_every_n_epochs': int,\n",
       " 'default_root_dir': typing.Union[str, pathlib.Path, NoneType],\n",
       " 'enable_autolog_hparams': bool,\n",
       " 'model_registry': typing.Optional[str],\n",
       " 'return': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.Trainer.__init__.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc.Iterable\n",
    "import datetime.timedelta  # TODO wrong, should be `from datetime import timedelta`\n",
    "import lightning.fabric.plugins.environments.cluster_environment.ClusterEnvironment\n",
    "import lightning.fabric.plugins.io.checkpoint_io.CheckpointIO  # TODO wrong, should be `from lightning.fabric.plugins.io.checkpoint_io import CheckpointIO`\n",
    "import lightning.pytorch.accelerators.accelerator.Accelerator\n",
    "import lightning.pytorch.callbacks.callback.Callback\n",
    "import lightning.pytorch.loggers.logger.Logger\n",
    "import lightning.pytorch.plugins.layer_sync.LayerSync\n",
    "import lightning.pytorch.plugins.precision.precision.Precision\n",
    "import lightning.pytorch.profilers.profiler.Profiler\n",
    "import lightning.pytorch.strategies.strategy.Strategy\n",
    "import pathlib.Path\n",
    "import t.Any  # TODO wrong, should be `from typing import Any`\n",
    "import t.Literal\n",
    "\n",
    "\n",
    "class __init___TypedDict(t.TypedDict, total=False):\n",
    "    self: t.Any\n",
    "    accelerator: str | lightning.pytorch.accelerators.accelerator.Accelerator\n",
    "    strategy: str | lightning.pytorch.strategies.strategy.Strategy\n",
    "    devices: list[int] | str | int\n",
    "    num_nodes: int\n",
    "    precision: (\n",
    "        t.Literal[64 | 32 | 16]\n",
    "        | t.Literal[\n",
    "            \"transformer-engine\"\n",
    "            | \"transformer-engine-float16\"\n",
    "            | \"16-true\"\n",
    "            | \"16-mixed\"\n",
    "            | \"bf16-true\"\n",
    "            | \"bf16-mixed\"\n",
    "            | \"32-true\"\n",
    "            | \"64-true\"\n",
    "        ]\n",
    "        | t.Literal[\"64\" | \"32\" | \"16\" | \"bf16\"]\n",
    "        | None\n",
    "    )\n",
    "    logger: (\n",
    "        lightning.pytorch.loggers.logger.Logger\n",
    "        | collections.abc.Iterable[lightning.pytorch.loggers.logger.Logger]\n",
    "        | bool\n",
    "        | None\n",
    "    )\n",
    "    callbacks: (\n",
    "        list[lightning.pytorch.callbacks.callback.Callback] | lightning.pytorch.callbacks.callback.Callback | None\n",
    "    )\n",
    "    fast_dev_run: int | bool\n",
    "    max_epochs: int | None\n",
    "    min_epochs: int | None\n",
    "    max_steps: int\n",
    "    min_steps: int | None\n",
    "    max_time: str | datetime.timedelta | dict[str | int] | None  # TODO wrong, should be ... dict[str, int] ...\n",
    "    limit_train_batches: float | int | None\n",
    "    limit_val_batches: float | int | None\n",
    "    limit_test_batches: float | int | None\n",
    "    limit_predict_batches: float | int | None\n",
    "    overfit_batches: int | float\n",
    "    val_check_interval: int | float | str | datetime.timedelta | dict[str | int] | None\n",
    "    check_val_every_n_epoch: int | None\n",
    "    num_sanity_val_steps: int | None\n",
    "    log_every_n_steps: int | None\n",
    "    enable_checkpointing: bool | None\n",
    "    enable_progress_bar: bool | None\n",
    "    enable_model_summary: bool | None\n",
    "    accumulate_grad_batches: int\n",
    "    gradient_clip_val: float | int | None\n",
    "    gradient_clip_algorithm: str | None\n",
    "    deterministic: bool | t.Literal[\"warn\"] | None\n",
    "    benchmark: bool | None\n",
    "    inference_mode: bool\n",
    "    use_distributed_sampler: bool\n",
    "    profiler: lightning.pytorch.profilers.profiler.Profiler | str | None\n",
    "    detect_anomaly: bool\n",
    "    barebones: bool\n",
    "    plugins: (\n",
    "        lightning.pytorch.plugins.precision.precision.Precision\n",
    "        | lightning.fabric.plugins.environments.cluster_environment.ClusterEnvironment\n",
    "        | lightning.fabric.plugins.io.checkpoint_io.CheckpointIO\n",
    "        | lightning.pytorch.plugins.layer_sync.LayerSync\n",
    "        | list[lightning.pytorch.plugins.precision.precision.Precision | lightning.pytorch.plugins.layer_sync.LayerSync]\n",
    "        | None\n",
    "    )\n",
    "    sync_batchnorm: bool\n",
    "    reload_dataloaders_every_n_epochs: int\n",
    "    default_root_dir: str | pathlib.Path | None\n",
    "    enable_autolog_hparams: bool\n",
    "    model_registry: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import lightning.pytorch.core.datamodule.LightningDataModule\n",
      "import pathlib.Path\n",
      "import pl.LightningModule\n",
      "import t.Any\n",
      "class Fit_TypedDict(t.TypedDict, total=False):\n",
      "    self: t.Any\n",
      "    model: pl.LightningModule\n",
      "    train_dataloaders: t.Any | lightning.pytorch.core.datamodule.LightningDataModule | None\n",
      "    val_dataloaders: Optional[t.Any] | None\n",
      "    datamodule: Optional[lightning.pytorch.core.datamodule.LightningDataModule] | None\n",
      "    ckpt_path: str | pathlib.Path | None\n",
      "    weights_only: Optional[bool] | None\n"
     ]
    }
   ],
   "source": [
    "UKS_TH_UTILS.func_to_typed_dict(L.Trainer.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pathlib.Path\n",
      "import t.Any\n",
      "class __init___TypedDict(t.TypedDict, total=False):\n",
      "    self: t.Any\n",
      "    save_dir: str | pathlib.Path\n",
      "    name: str | None\n",
      "    version: int | str | None\n",
      "    prefix: str\n",
      "    flush_logs_every_n_steps: int\n"
     ]
    }
   ],
   "source": [
    "UKS_TH_UTILS.func_to_typed_dict(CSVLogger.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define any number of nn.Modules (or use your current ones)\n",
    "encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "\n",
    "# define the LightningModule\n",
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self, encoder: nn.Sequential, decoder: nn.Sequential):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def training_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = nn.functional.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n",
    "        # this is the validation loop\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        val_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "\n",
    "    def test_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n",
    "        # this is the test loop\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kret_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
